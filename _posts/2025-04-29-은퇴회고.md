---
comments: true
title: 개발자 은퇴 회고, LLM 공부, 구직 에이전트 개발기 (미완)
key: 202504290
picture_frame: shadow
tags:
  - DevOps
---

> 개인사와 사견이 많이 포함돼 있습니다. 제 사고의 시간 순서대로 쓰여졌습니다.

<!--more-->

# 일 년를 돌아보며

서른이 되며 인생을 다시 설계해 보겠다는 포부를 안고 퇴사한 지 어느덧 1년이 지났다. 한가롭게 대전에서 졸업 학기를 보내던 시기도 있었지만, 기다렸다는 듯 개인적인 일들이 큰 장벽처럼 밀려와 정신없이 시간이 흘러갔다. 대치동식 사교육부터 개발자 병특까지 정해진 흐름에 올라탄 느낌이 있었기에 “그때 과학고 준비반에 들어가지 않았다면 지금쯤 어떤 삶을 살고 있었을까?”라는 물음은 이번 갭이어의 중심에 있었고, 지금까지의 시간에 대한 일종의 보상 심리도 함께 작용했다. 혼자 보내는 시간이 많았던 만큼, 몇 가지 부업도 시도해 보고 취미로만 즐기던 일을 본격적으로 공부해 보기도 했다. 그렇게 가능성을 탐색하다 보니, 여러 가지 이유로 결국 ‘개발자’라는 직업이 나에게 가장 잘 맞는다는 확신이 들었다. 한번 스스로를 되돌아보는 시간을 가졌으니 다시 일하고 싶었다. 팀에 몰입하고 그 안에 생기는 불규칙을 그전보다 나은 모습으로 대하고 싶었다.

다시 시작한다면 어떤 개발자가 되어야 할까. 휴식기를 갖기 전, 나는 데브옵스와 데이터 엔지니어를 거치며 플랫폼 중심의 경험을 쌓아왔다. 그 과정에서 줄곧 ML 도메인에서 직접적으로 기여하고 싶다는 마음은 있었다. 다만 커리어 후반부에 맡았던 MLOps 업무에서 생기는 비효율에 대한 어려움과 의문들을 꽤 가졌고, 이제 다시 구직을 한다면, 아예 대기업 규모에서 ML 플랫폼을 다루는 포지션, 혹은 End-to-End로 AI프로덕트에 기여할 수 있는 포지션을 고려했다. 후자를 택한다면, 최신 모델 구조와 평가 기법 등에 대한 이해를 논문 단위에서 다시 쌓아야 하기에, 기반 지식을 정리할 필요가 있다. 개인 사정상 해외에 거주 중이라 앞으로도 한동안 취업이 어려우니 괜찮은 선택인 것 같았다.

이 과정에서 외부 스터디에서 만나 좋은 인상을 받았던 분과, 평소 눈 여겨봤던 커리어패스를 가진 분에게 조언을 구한 적이 있다. 대체로 파운데이션 모델이 나온뒤로 중소형 회사 중심으로 풀스택으로 AI프로덕트에 기여하는 포지션 수요가 증가하고 있다는 이야기를 들었다. 개인적인 경험으로도, 나는 학습 플랫폼과 배치 파이프라인을 운영하면서 데이터 과학자들의 실험 반복에 무리가 없도록 지원하는 역할을 맡은 적이 있다. 그런데 내가 있던 기간 동안 임팩트를 만들어내는 데이터 과학자 분들은 그런 문제를 겪기보다는, 이미 학습된 모델이나 이를 감싸는 오픈소스를 어떻게 비즈니스에 접목시킬지, 또는 비교적 간단한 모델로 어떻게 실질적인 가치를 만들어낼지에 더 많은 관심을 두고 있었다. 이러한 프로젝트에서는 플랫폼 차원에서 범용적인 추상화를 시도하기보다는, 개별적으로 배포나 트러블슈팅을 지원할 수밖에 없었다. 다만 돌아보면, 당시 대부분의 프로덕트가 구상 단계에 있었고, 업무의 범주가 확장되고 정리되는 초기 과정에 있었기 때문이었다. ML제품은 결국 실험을 통해 개선되고 전달된다. 이때 광고타겟팅과 추천시스템 같은 일반적인 ML서비스의 구조에 대해 잘 이해하고, 앞으로 만들어질 것들과 실험의 중요성을 인지하고 있었다면 더 좋은 판단을 할 수 있었을 것이다. 앞선 생각으로 리드 분과 이야기를 나눴던 적도 있는데, 당시 큰 그림에 공감하고 긴 호흡으로 기여하지 못한 점이 아쉬움으로 남는다.

그렇게 자연스럽게 MLE 혹은 ML 도메인에서의 데이터 엔지니어 포지션을 다시 살펴보게 되었다. 눈에 띄는 변화는 채용 공고 대부분에 LLM 언급이 중심적으로 등장하고 있다는 점이었다. 오랜만에 들어가기 시작한 링크드인에도 `Building LLMs @어떤 회사` 계정이 많이 보였다. LLM의 등장은 이미 업계 전반에 걸친 지각 변동으로 예견되어 있었지만, 내가 퇴사를 결심했던 시점은 LLM 기반 프로덕트가 본격적으로 적용되기 시작하던 초기 단계였다. 이후 사이드 프로젝트를 진행하며 ChatGPT를 활용해 왔지만, 당시에는 개발자로 커리어를 계속 이어갈 생각이 아니었기에 sLLM, RAG, AI Agent와 같은 관련 기술 흐름에는 깊은 관심을 두지 못했다. 해외에 있는 시간이 지나고 나면 LLM이 더 부각될거라 생각해서, 주어진 시간 안에 관련 자료와 적용 사례를 찾아보았고 어느 정도 공부와 적당한 핸즈온 경험을 쌓기로 마음먹게 되었다.

# LLM, RAG, AI Agent?

> 개인적으로 블로그에는 많은 설명을 하기 보다는 최대한 탑다운 방식으로 내용 정리를 하려 합니다.

## 접근 방법

위 기술의 아주 일반적인 사례는 제외하고, 인상적인 사례들을 찾아보고 내용을 요약해보려 한다. RAG, AI Agent가 발전해온 과정은 생략한다. 또한 파인튜닝이나 파운데이션 모델 구조를 분석해야하는 내용보다, 어떻게 버티컬서비스에 적용하고 있는가를 기준으로 훑어보려 한다. [Eugene Yan의 블로그](https://eugeneyan.com/)와 [VESSL AI](https://www.youtube.com/@vesslai)의 유튜브가 큰 도움이 되었다.

## Amazon

### 아마존 뮤직 플레이리스트 검색 시스템 개선

기존에 키워드 매칭 기반 플레이리스트 검색 시스템을 LLM을 이용해 시멘틱 검색 모델로 개선했다.

#### 문제점
- 커뮤니티의 플레이리스트는 메타데이터가 부족한 경우가 많아서 시멘틱 검색 모델 학습에 어려움이 있었다.
- 기존 훈련데이터 `<검색어, 클릭된 플레이리스트>` 데이터가 신규(시멘틱 검색) 모델 학습에 적합하지 않다.
- 모델 성능을 평가하기 위한 라벨링 작업이 비싸다.

#### 해결방법
![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/llm/0.png)
- 메타데이터가 부족한 플레이리스트는 LLM 큐레이터 모델이 첫 15곡을 기반으로 상세설명을 생성한다.
    - 이는 30B 모델을 파인튜닝해 사용함. 에디터 플레이리스트와 설명이 존재하는 플레이리스트 데이터를 이용함.
- LLM 라벨러 모델을 통해 학습데이터를 생성했다.
    - 플레이리스트 메타데이터를 통해 검색어를 생성한다.
    - 로그의 검색율이 좋지 않았던 검색어를 이용해 플레이리스트를 찾아내어 ‘어려운’ 검색어에 대한 학습 데이터를 추가한다.
        - 이 과정에서는 아마존 자체 텍스트 임베딩과 작은 LLM 모델을 사용한다. (자세히 설명하지 않음)
    - 생성된 학습 데이터에 대해 라벨러가 Positive/Negative 라벨링을 한다.
- LLM 심사관을 통해 평가를 자동화한다.
    - 자세한 설명은 없다.
    - 데일리 모니터링에도 사용함.

### 참고: LLM-as-Judge

![text](https://raw.githubusercontent.com/q0115643/my_blog/master/assets/images/llm/1.png)

https://eugeneyan.com/writing/llm-evaluators/

#### 평가 방법
- Direct scoring (객관적 평가에 적합)
- Pairwise comparison (주관적 평가에 적합)
- Reference-based (응답에 포함되어야 할 정보를 비교)

#### 평가자 평가방법
- 분류 기반 지표 (precision, recall, …)
  - 해석 용이
- 상관(correlation) 기반 지표
  - kappa, tau, rho
  - 우연한 일치를 고려하지 않거나, 제품 성능으로 직결하기 어려워 최대한 분류 기반 지표를 사용하는게 좋음

#### 장점
- 인간 평가보다 비용이 적게 들고 빠르다.
- 모델, 랜덤 시드와 하이퍼 파라미터가 같다면 같은 평가의 재현성이 높다.
- 확장 가능하여 모니터링에 사용할 수 있다.

####  주의점
- LLM 평가가 신뢰할 수 있는지 검증하려면, 일부 샘플에 대해 사람 평가와 비교해야한다.
- 앙상블 방식으로 여러 평가 모델을 사용해 편향을 줄이고 안정화 시킬 수 있다.
- 순서를 랜덤화해서 LLM이 첫 번째와 마지막 질문에 집중하는 bias를 줄여야 함
- LLM이 짧은 답변 선호 경향이 있다. 선호도의 기준에 대한 지시를 명확히 하는게 좋다.
- CoT: 최종 판단 전에 이유나 단계별 분석을 설명하도록 요구한다.
